# -*- coding: utf-8 -*-
"""Ice Detection.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1ZbYqCjruhMtKy4hYnEFV9QHuoJtjQphL
"""

import tensorflow as tf

import os

#avoid oom errors by setting GPU memory consumption growth
gpus=tf.config.experimental.list_logical_devices('GPU')
for gpu in gpus:
  tf.config.experimental.set_memory_growth(gpu,True)

"""Removal of dodgy images"""

import cv2
import imghdr
from matplotlib import pyplot as plt

data_dir='sample_data'
image_exts=['jpg','jpeg','png']

os.listdir(data_dir)

img=cv2.imread('/content/sample_data/Ice/image.jpg',0)
print(img)
print(img.shape)
plt.imshow(cv2.cvtColor(img,cv2.COLOR_BGR2RGB))

"""What we did is that we remove all the images which are of less size as they may be blur, not of good quality and many more."""

for image_class in os.listdir(data_dir):
  for image in os.listdir(os.path.join(data_dir,image_class)):
      image_path=os.path.join(data_dir,image_class, image)
      try:
        img=cv2.imread(image_path)
        tip=imghdr.what(image_path)
        if tip not in image_exts:
          print("Image not in exts list{}".format(image_path))
          os.remove(image_path)
      except:
        print("Issue with images {}".format(image_path))

"""Loading of Data"""

import numpy as np
from matplotlib import pyplot as plt

data=tf.keras.utils.image_dataset_from_directory('sample_data')  # building the data pipeline
data

data = data.shuffle(buffer_size=100)
data_iterator=data.as_numpy_iterator() #accessing the pipeline by loop

batch=data_iterator.next() #grabs one batch size

batch[0].shape  #Image represented as numpy array

batch[1]

fig, ax=plt.subplots(ncols=6, figsize=(20,20))
for idx, img in enumerate(batch[0][:6]):
  ax[idx].imshow(img.astype(int))
  ax[idx].title.set_text(batch[1][idx])

"""**PREPROCESS DATA**"""

data = data.map(lambda x,y:(x/255 ,y))

scalar_iterator=data.as_numpy_iterator()  #next defines the suffling of the data if we don't use next() then the same will be printed
batch=scalar_iterator.next()
batch

batch[0].min()

fix, ax=plt.subplots(ncols=4, figsize=(20,20))
for idx, img in enumerate(batch[0][:4]):
  ax[idx].imshow(img)
  ax[idx].title.set_text(batch[1][idx])

"""**Spliting of the data**

**Heat Map of the images**
"""

import seaborn as sns
import matplotlib.pyplot as plt

# Assuming batch[0] contains your image data
images = batch[0][:2]

# Create a subplot with 1 row and 2 columns
fig, ax = plt.subplots(ncols=2, figsize=(20, 10))

# Iterate over each image
for idx, img in enumerate(images):
    # Flatten each channel individually
    flattened_img = img.reshape(-1, img.shape[-1])

    # Create a heatmap for each channel
    for channel in range(img.shape[-1]):
        channel_data = flattened_img[:, channel]
        channel_data_2d = channel_data.reshape(img.shape[:-1])
        sns.heatmap(channel_data_2d, cmap='hot', cbar_kws={'label': f'Pixel Intensity (Channel {channel})'}, ax=ax[idx])
        ax[idx].axis('off')

plt.show()

import seaborn as sn
images=batch[0][:4]
fix, ax=plt.subplots(nrows=4, ncols=3, figsize=(20,10))
for idx, img in enumerate(images):

    flattened_img = img.reshape(-1, img.shape[-1])

    for channel in range(img.shape[-1]):
        channel_data = flattened_img[:, channel]
        channel_data_2d = channel_data.reshape(img.shape[:-1])
        sn.heatmap(channel_data_2d, cmap='hot', cbar_kws={'label': f'Pixel Intensity (Channel {channel})'}, ax=ax[idx, channel])
        ax[idx, channel].axis('off')
        ax[idx, channel].set_title(f"Label: {batch[1][idx]}")

plt.tight_layout()

plt.show()

len(data)

train_size=int(len(data)*0.7)
val_size=int(len(data)*0.2)
test_size=int(len(data)*0.1)

train_size+val_size+test_size

train=data.take(train_size)
val=data.skip(train_size).take(val_size)
test=data.skip(train_size+val_size).take(test_size)

"""**Model Building**"""

from tensorflow.keras.models import Sequential
from tensorflow.keras.layers import Conv2D, MaxPooling2D, Dense, Flatten
#conv2d-> 2D convolutional layer
#Maxpooling layer -> condense the images
#Dropout -> used for regularization

#adding a convolutional layer and a maxpool layer. 1st layer has 16 filter which condense
  #to good classification (3,3) describe the pixel of image and 1 describe the movement
  #i.e. move by 1 pixel each time
  #relu make all negative values to 0 and positive remains the same
  #sigmoid function gives 0 for negative and +1 for positive output

  model=Sequential()

  model.add(Conv2D(16,(3,3), 1, activation='relu', input_shape=(256,256,3)))
  model.add(MaxPooling2D())

  model.add(Conv2D(32, (3,3), 1, activation='relu'))
  model.add(MaxPooling2D())

  model.add(Conv2D(16, (3,3), 1, activation='relu'))
  model.add(MaxPooling2D())

  model.add(Flatten())


  model.add(Dense(256, activation='relu'))
  model.add(Dense(1, activation='sigmoid'))

model.compile('adam', loss=tf.losses.BinaryCrossentropy(), metrics=['accuracy'])
#adam is an optimizer

model.summary()

"""**Training of the data**"""

logdir='logs'

tensorboard_callback=tf.keras.callbacks.TensorBoard(log_dir=logdir)

hist=model.fit(train, epochs=20, validation_data=val, callbacks=[tensorboard_callback])

hist.history

"""**Performance Analysis**"""

fig=plt.figure()
plt.plot(hist.history['loss'], color='teal', label='loss')
plt.plot(hist.history['val_loss'], color='orange', label='val_loss')
fig.suptitle("Loss",fontsize=20)
plt.legend(loc="upper right")
plt.show()

fig=plt.figure()
plt.plot(hist.history['accuracy'], color='teal', label='accuracy')
plt.plot(hist.history['val_accuracy'], color='orange', label='val_accuracy')
fig.suptitle("Accuracy",fontsize=20)
plt.legend(loc="upper left")
plt.show()

"""**Evalution of the Model**"""

from tensorflow.keras.metrics import Precision, Recall, BinaryAccuracy

precision=Precision()
recall=Recall()
binaryAccuracy=BinaryAccuracy()

for batch in test.as_numpy_iterator():
  X,y=batch
  yhat=model.predict(X)
  precision.update_state(y, yhat)
  recall.update_state(y, yhat)
  binaryAccuracy.update_state(y, yhat)

print(f'Precision:{precision.result().numpy()}, Recall:{recall.result().numpy()}, BinaryAccuracy{binaryAccuracy.result().numpy()}')

"""**Testing**"""

import cv2

img=cv2.imread('/content/th-26-_png.rf.98e124ffc0362f97c9595238c645c91e.jpg')
plt.imshow(cv2.cvtColor(img, cv2.COLOR_BGR2RGB))
plt.show()

resize=tf.image.resize(img,(256,256))
plt.imshow(resize.numpy().astype(int))
plt.show

yhat=model.predict(np.expand_dims(resize/255, 0))

yhat[0]

if yhat>0.5:
  print("No ice detected")
else:
  print("Ice present on the road")

